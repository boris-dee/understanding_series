{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Series we are going to look at some properties of discrete random variables that will be useful for the future Series on classification metrics. The rigorous mathematical theory behind random variables is clearly indigest, and we are not going to look into it, because we don't need it. Instead, we are going to define a random variable as a simple numerical variable, the value of which is impossible to predict. We won't need more than this definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Definition\n",
    "> **A random variable $X$ is a numerical variable, the value of which, determined by the result of an experiment, is impossible to predict. The random variable is said to be discrete if the number of its realizations is countable**.\n",
    "\n",
    "Examples:\n",
    "- Throw a dice, the variable $X$ associated to the face obtained is a discrete random variable. $X\\in [1,2,3,4,5,6]$.\n",
    "- Any binary variable $X$ is a quantitative discrete variable, e.g. sick/not sick, open/closed, left/right, green/red, woman/man, etc. In this case, $X\\in\\{0,1\\}$.\n",
    "\n",
    "For each of the realization $x_i$ of the random variable $X$, we can define a **probability of occurence** $p_i=P(X=x_i)$, comprised between $0$ and $1$. This reads \"$p_i$ is the probability that $X$ equals $x_i$\".\n",
    "\n",
    "For instance, when we throw a dice, we have $p_4 = P(X=4)=1/6$.\n",
    "\n",
    "> **The set of all pairs $(x_i,p_i)$ forms a probability distribution if $\\forall i, \\sum p_i=1$**.\n",
    "\n",
    "In other words, when we sum all probabilities of all realizations of $X$, we obtain $100\\%$.\n",
    "\n",
    "Note that there are two ways of defining a probability:\n",
    "1. The **Bayes** way: for Bayes, the probability of an event is defined as the **degree of confidence** that this event is going to occur. For instance, when we say there's a 40% probability that it's going to rain tomorrow, this is a Bayesian probability. We are 40% confident that it's going to rain.\n",
    "2. The **Laplace** way: because Laplace did not understand Bayesian probabilities, he formulated them in terms of the **frequency of occurrence**. For instance, when we say there's a 50% chance of having tails in a coin toss, this is a Laplacian probability. If we repeat this experience 10.000 times, we will, on average, get 5.000 tails. The Laplacian view of probabilities is more intuitive, but cannot account for all probabilities. For instance, it is impossible to interpret a 40% chance of raining in terms of Laplacian probabilities.\n",
    "\n",
    "Later in these Series, when we deal with accuracy metrics in machine learning, we will mainly use Laplacian probabilities.\n",
    "\n",
    "When dealing with discrete random variables, it is useful to gather all pairs $(x_i,p_i)$ in a lookup table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
